# Titanic Survival Prediction: Deep Learning Approach

## Descripci칩n
Este proyecto aborda la cl치sica competici칩n de Kaggle sobre el Titanic utilizando un enfoque de **Deep Learning** con TensorFlow/Keras. Este an치lisis se centra en la inspecci칩n detallada del dataframe de entrenamiento (en especial para los 췂features췂 de Tickets y Cabinas) para alimentar una Red Neuronal Densa.

## >> Tecnolog칤as Utilizadas
- **Python 3**
- **TensorFlow / Keras:** Construcci칩n del modelo de red neuronal.
- **Scikit-Learn:** Preprocesamiento (OneHotEncoder, SimpleImputer) y Pipelines.
- **Pandas & NumPy:** Manipulaci칩n de datos.

## 游 Arquitectura del Modelo
El modelo es una Red Neuronal Secuencial (Feed-Forward) dise침ada para evitar el sobreajuste (Overfitting) en un dataset peque침o:
- **Input Layer:** Preprocesamiento mediante `ColumnTransformer`.
- **Hidden Layers:** Capas densas con activaci칩n `elu` (cuya eficacia supera a 췂relu췂).
- **Regularizaci칩n:** Uso intensivo de `BatchNormalization` y `Dropout (0.3)` para robustez.
- **Output Layer:** Activaci칩n `Sigmoid` para clasificaci칩n binaria.

## 游늵 Feature Engineering (Ingenier칤a de Caracter칤sticas)
Uno de los puntos clave de este notebook es el tratamiento de variables categ칩ricas complejas:
1.  **Tickets:** Se identificaron tickets compartidos (familias/grupos de conocidos) y se agruparon los tickets 칰nicos o con frecuencias de aparici칩n debajo de 4, bajo la etiqueta `Other_ticket` para reducir la dimensionalidad. Se ha observado una correspondencia entre la probabilidad de supervivencia y el ticket en com칰n.
2.  **Cabinas:** Estrategia similar para reducir el ruido de las cabinas con aparici칩n 칰nica. Tambi칠n se ha observado una correlaci칩n entre la tasa de superviviencia y el n칰mero de cabina.
3.  Los elementos num칠ricos desconocidos son reemplazados por el valor medio mediante la imputaci칩n, y los categ칩ricos mediante one hot encoder.

## 游늳 Resultados del Entrenamiento
El modelo utiliza **Early Stopping** para detener el entrenamiento cuando la p칠rdida de validaci칩n deja de mejorar, asegurando el mejor modelo posible. Se ha utilizado el mecanismo 췂adam췂 para optimizar el 췂learning rate췂. La precisi칩n m치s alta alcanzada por el modelo entrenado con respecto a los datos de validaci칩n ha sido del alrededor del 85%.
Este proyecto sirve como introducci칩n al mundo de data science y machine learning y mejoras del modelo son posibles con una experimentaci칩n m치s exhaustiva de los par치metros y la estructura de la red.

![Curva de Entrenamiento](images/training_history.png)
*(Gr치fica de Binary_Accuracy vs Val_Binary_Accuracy con respecto a iteraciones)*

## 游 C칩mo ejecutar este proyecto
1. Clonar el repositorio.
2. Instalar las dependencias:
   ```bash
   pip install -r requirements.txt

## 九뉦잺 Autor
**Lorenzo Ji** - *Proyecto personal con recursos proporcionado por Kaggle*
* Perfil de GitHub: https://github.com/Lorsimu
* Correo acad칠mico: lorenzo.ji@estudiante.uam.es


