# Titanic Survival Prediction: Deep Learning Approach

## DescripciÃ³n
Este proyecto aborda la clÃ¡sica competiciÃ³n de Kaggle sobre el Titanic utilizando un enfoque de **Deep Learning** con TensorFlow/Keras. Este anÃ¡lisis se centra en la inspecciÃ³n detallada del dataframe de entrenamiento (en especial para los Â´featuresÂ´ de Tickets y Cabinas) para alimentar una Red Neuronal Densa.

## ğŸ› ï¸ TecnologÃ­as Utilizadas
- **Python 3**
- **TensorFlow / Keras:** ConstrucciÃ³n del modelo de red neuronal.
- **Scikit-Learn:** Preprocesamiento (OneHotEncoder, SimpleImputer) y Pipelines.
- **Pandas & NumPy:** ManipulaciÃ³n de datos.

## ğŸ§  Arquitectura del Modelo
El modelo es una Red Neuronal Secuencial (Feed-Forward) diseÃ±ada para evitar el sobreajuste (Overfitting) en un dataset pequeÃ±o:
- **Input Layer:** Preprocesamiento mediante `ColumnTransformer`.
- **Hidden Layers:** Capas densas con activaciÃ³n `elu` (cuya eficacia supera a Â´reluÂ´).
- **RegularizaciÃ³n:** Uso intensivo de `BatchNormalization` y `Dropout (0.3)` para robustez.
- **Output Layer:** ActivaciÃ³n `Sigmoid` para clasificaciÃ³n binaria.

## ğŸ“Š Feature Engineering (IngenierÃ­a de CaracterÃ­sticas)
Uno de los puntos clave de este notebook es el tratamiento de variables categÃ³ricas complejas:
1.  **Tickets:** Se identificaron tickets compartidos (familias/grupos de conocidos) y se agruparon los tickets Ãºnicos o con frecuencias de apariciÃ³n debajo de 4, bajo la etiqueta `Other_ticket` para reducir la dimensionalidad. Se ha observado una correspondencia entre la probabilidad de supervivencia y el ticket en comÃºn.
2.  **Cabinas:** Estrategia similar para reducir el ruido de las cabinas con apariciÃ³n Ãºnica. TambiÃ©n se ha observado una correlaciÃ³n entre la tasa de superviviencia y el nÃºmero de cabina.
3.  Los elementos numÃ©ricos desconocidos son reemplazados por el valor medio mediante la imputaciÃ³n, y los categÃ³ricos mediante one hot encoder.

## ğŸ“ˆ Resultados del Entrenamiento
El modelo utiliza **Early Stopping** para detener el entrenamiento cuando la pÃ©rdida de validaciÃ³n deja de mejorar, asegurando el mejor modelo posible. Se ha utilizado el mecanismo Â´adamÂ´ para optimizar el Â´learning rateÂ´. La precisiÃ³n mÃ¡s alta alcanzada por el modelo entrenado con respecto a los datos de validaciÃ³n ha sido del alrededor del 85%.
Este proyecto sirve como introducciÃ³n al mundo de data science y machine learning y mejoras del modelo son posibles con una experimentaciÃ³n mÃ¡s exhaustiva de los parÃ¡metros y la estructura de la red.

![Curva de Entrenamiento](images/training_history.png)
*(GrÃ¡fica de Binary_Accuracy vs Val_Binary_Accuracy con respecto a iteraciones)*

## ğŸš€ CÃ³mo ejecutar este proyecto
1. Clonar el repositorio.
2. Instalar las dependencias:
   ```bash
   pip install -r requirements.txt

